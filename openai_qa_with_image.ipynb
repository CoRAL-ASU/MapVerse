{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24eada1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /home/vivek/.local/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /home/vivek/.local/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: torch in /home/vivek/.local/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: cairosvg in /home/vivek/.local/lib/python3.10/site-packages (2.8.2)\n",
      "Requirement already satisfied: tqdm in /home/vivek/.local/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: openai in /home/vivek/.local/lib/python3.10/site-packages (1.107.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vivek/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vivek/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/vivek/.local/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vivek/.local/lib/python3.10/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vivek/.local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vivek/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vivek/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vivek/.local/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: fsspec in /home/vivek/.local/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: jinja2 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: filelock in /home/vivek/.local/lib/python3.10/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: networkx in /home/vivek/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/vivek/.local/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.4.0->torch) (59.6.0)\n",
      "Requirement already satisfied: cairocffi in /home/vivek/.local/lib/python3.10/site-packages (from cairosvg) (1.7.1)\n",
      "Requirement already satisfied: cssselect2 in /home/vivek/.local/lib/python3.10/site-packages (from cairosvg) (0.8.0)\n",
      "Requirement already satisfied: tinycss2 in /home/vivek/.local/lib/python3.10/site-packages (from cairosvg) (1.2.1)\n",
      "Requirement already satisfied: defusedxml in /home/vivek/.local/lib/python3.10/site-packages (from cairosvg) (0.7.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vivek/.local/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vivek/.local/lib/python3.10/site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/vivek/.local/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: sniffio in /home/vivek/.local/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vivek/.local/lib/python3.10/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/vivek/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vivek/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vivek/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vivek/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vivek/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vivek/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vivek/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.1.0 in /home/vivek/.local/lib/python3.10/site-packages (from cairocffi->cairosvg) (1.15.1)\n",
      "Requirement already satisfied: webencodings in /home/vivek/.local/lib/python3.10/site-packages (from cssselect2->cairosvg) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vivek/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pycparser in /home/vivek/.local/lib/python3.10/site-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.21)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas matplotlib torch cairosvg tqdm openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44148764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cairosvg\n",
    "import numpy as np\n",
    "import io\n",
    "import math\n",
    "import sys\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "MODEL_NAME = \"gpt-4o\"   # Vision-language model\n",
    "# Initializing OpenAI client - see https://platform.openai.com/docs/quickstart?context=python\n",
    "OPENAI_KEY = \"<OPENAI_KEY>\"\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "CUSTOM_PROMPT = \"\"\"\n",
    "You are an AI Agent with specilaised knowledge in reading and understanding map data. Analyze the following map and using information from the steps and examples given below, answer the question.\n",
    "\n",
    "Steps to follow:\n",
    "\n",
    "Identify Map-Related Elements in the Question\n",
    " Carefully understand the question to determine the key geographical features, locations, or spatial characteristics it refers to.\n",
    "\n",
    "\n",
    "Locate the Identified Elements on the Map\n",
    " Find and observe these features or entities on the map provided. Pay attention to patterns, distributions, directions, scales, or any visual cues.\n",
    "\n",
    "\n",
    "Apply Logical Reasoning\n",
    " Use spatial reasoning and contextual clues from the map to draw connections between the question and the observed map features.\n",
    "\n",
    "\n",
    "Formulate a Concise Answer\n",
    " Based on your reasoning, arrive at a clear and accurate answer. Return only a word or phrase, as requiredâ€”no explanation is needed. \n",
    " If adequate data is not present, give answer as \"no data\". \n",
    " If you have all the data and there is no answer to the question, give answer \"none\". If it is a counting problem, give answer 0. \n",
    " If you have all the data and it is not possible to answer the question, give answer \"not possible\".\n",
    "\n",
    "Assuming we are talking about a map with election results for USA. This  map contains  the voter breakdown across the United States, including the number of votes cast and the winning party in each state. Some examples of questions and there answers are as follows:\n",
    "\n",
    "\n",
    "Question: Count the number states on the west coast where Democrats won.\n",
    "Answer: 3\n",
    "\n",
    "\n",
    "Questions: Based on the information given in the map, who won the election, Democrats or Republicans?\n",
    "Answer: Democrats\n",
    "\n",
    "Questions: Based on the information given in the map, if both Democrats and Republicans win 25 states each, do we have more blue states or red states?\n",
    "Answer: neither\n",
    "\n",
    "Question: List the top 4 states in terms of seats where the republicans won\n",
    "Answer: Texas, Georgia, Missouri, Tenessee\n",
    "\n",
    "Question: Rank these states in ascending order of seats - kansas, south carolina, nebraska, oklahoma, colorado, wisconsin\n",
    "Answer: nebraska, kansas, oklahoma, south carolina, colorado, wisconsin\n",
    "\n",
    "Question: Based on reasoning, Answer the following:\n",
    "     Montana : Wyoming :: North Dakota : ?\n",
    "Answer: South Dakota\n",
    "\n",
    "Now, Answer the Question below based on the information, instruction and examples above:\n",
    "\n",
    "\"\"\"\n",
    "INPUT_CSV = \"data/typed_questions.csv\"\n",
    "OUTPUT_CSV = f\"results/{MODEL_NAME.split('/')[-1]}_results.csv\"  \n",
    "IMAGE_BASE_FOLDER = \"data/imgs/\"\n",
    "\n",
    "# ---- HELPER FUNCTIONS ----\n",
    "def find_image_recursive(base_folder: str, image_name: str) -> str | None:\n",
    "    \"\"\"Recursively find image by filename in base_folder. Returns full path or None.\"\"\"\n",
    "    for root, _, files in os.walk(base_folder):\n",
    "        if image_name in files:\n",
    "            return os.path.join(root, image_name)\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_image_safely(image_path: str, output_format: str = \"PNG\"):\n",
    "    \"\"\"\n",
    "    Load an image safely and return a base64-encoded data URI.\n",
    "    Supports PNG, JPEG, GIF, WEBP, and SVG.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def ask_image_question(image_path: str, question: str, custom_prompt: str, index:int) -> str:\n",
    "    image = load_image_safely(image_path)\n",
    "    if image is None:\n",
    "        return \"Error loading image\"\n",
    "    \n",
    "    # âœ… OpenAI requires chat template\n",
    "    task = {\n",
    "        \"custom_id\": f\"task-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # This is what you would have in your Chat Completions API call\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"temperature\": 0.0,\n",
    "            \"max_tokens\": 128,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": custom_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": question\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{image}\"\n",
    "                            }\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ]            \n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return task\n",
    "\n",
    "# Load already answered pairs from output CSV to a set for quick lookup\n",
    "def load_already_answered(output_csv):\n",
    "    answered_set = set()\n",
    "    try:\n",
    "        df_out = pd.read_csv(output_csv)\n",
    "        for _, row in df_out.iterrows():\n",
    "            answered_set.add( (row['image_name'], row['question']) )\n",
    "    except FileNotFoundError:\n",
    "        # Output file does not exist yet\n",
    "        pass\n",
    "    return answered_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183e5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(input_csv, output_csv, base_folder, custom_prompt):\n",
    "    answered_pairs = load_already_answered(output_csv)\n",
    "    df_all = pd.read_csv(input_csv)\n",
    "    batch_size = 100\n",
    "    n_batches = math.ceil(len(df_all) / batch_size)\n",
    "    start_idx = 0 \n",
    "    j = start_idx\n",
    "    for i in range(n_batches):\n",
    "        tasks = []\n",
    "        index_to_meta = {}\n",
    "\n",
    "        # Collect until we have 100 valid tasks or we exhaust df_all\n",
    "        while len(tasks) < batch_size and j < len(df_all):\n",
    "            row = df_all.iloc[j]\n",
    "            image_name, question = row['image_name'], row['question']\n",
    "            j += 1  # move pointer no matter what\n",
    "\n",
    "            # Skip if already answered\n",
    "            if (image_name, question) in answered_pairs:\n",
    "                continue\n",
    "\n",
    "            image_path = find_image_recursive(base_folder, image_name)\n",
    "\n",
    "            try:\n",
    "                if not image_path:\n",
    "                    # Directly save \"Image not found\"\n",
    "                    with open(output_csv, mode='a', newline='', encoding='utf-8') as f_out:\n",
    "                        writer = csv.DictWriter(f_out, fieldnames=[\"image_name\", \"question\", \"llm_answer\"])\n",
    "                        if f_out.tell() == 0:\n",
    "                            writer.writeheader()\n",
    "                        writer.writerow({\n",
    "                            \"image_name\": image_name,\n",
    "                            \"question\": question,\n",
    "                            \"llm_answer\": \"Image not found\"\n",
    "                        })\n",
    "                else:\n",
    "                    task = ask_image_question(image_path, question, custom_prompt, j)\n",
    "                    tasks.append(task)\n",
    "                    index_to_meta[f\"task-{j}\"] = (image_name, question)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error processing {image_name} - {question}: {e}\")\n",
    "                \n",
    "        # If no tasks left, stop early\n",
    "        if not tasks:\n",
    "            print(\"âœ… No new tasks to run.\")\n",
    "            continue\n",
    "\n",
    "        # Creating the file\n",
    "        file_name = f\"openai_results/batch_tasks_mapqa_{i}.jsonl\"\n",
    "        with open(file_name, 'w') as file:\n",
    "            for obj in tasks:\n",
    "                file.write(json.dumps(obj) + '\\n')\n",
    "        # Uploading the file \n",
    "        batch_file = client.files.create(\n",
    "            file=open(file_name, \"rb\"),\n",
    "            purpose=\"batch\"\n",
    "        )\n",
    "        \n",
    "        print(i, j, batch_file.id)\n",
    "        \n",
    "        # Creating the job\n",
    "        batch_job = client.batches.create(\n",
    "            input_file_id=batch_file.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45570e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_csv(INPUT_CSV, OUTPUT_CSV, IMAGE_BASE_FOLDER, CUSTOM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7a578d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def submit_batches(input_csv, base_folder, custom_prompt, batch_metadata_file=\"openai_results/batch_jobs_metadata_4o.json\"):\n",
    "    \"\"\"\n",
    "    Submit batch jobs in chunks of 100 while avoiding duplication.\n",
    "    Already submitted chunks are skipped.\n",
    "    \"\"\"\n",
    "    # Load existing metadata or start fresh\n",
    "    try:\n",
    "        with open(batch_metadata_file, \"r\") as f:\n",
    "            batch_metadata = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        batch_metadata = []\n",
    "\n",
    "    submitted_indices = {meta[\"start_index\"] for meta in batch_metadata}\n",
    "\n",
    "    # Read input CSV in chunks\n",
    "    for chunk_start, chunk in enumerate(pd.read_csv(input_csv, chunksize=100)):\n",
    "        start_index = chunk_start * 100\n",
    "        if start_index in submitted_indices:\n",
    "            print(f\"â© Skipping chunk starting at index {start_index}, already submitted\")\n",
    "            continue\n",
    "\n",
    "        df = chunk\n",
    "        tasks = []\n",
    "        index_to_meta = {}\n",
    "\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Preparing tasks for chunk starting at {start_index}\"):\n",
    "            image_name, question = row['image_name'], row['question']\n",
    "            image_path = find_image_recursive(base_folder, image_name)\n",
    "\n",
    "            if not image_path:\n",
    "                print(f\"âš ï¸ Image not found: {image_name}\")\n",
    "                continue\n",
    "\n",
    "            task = ask_image_question(image_path, question, custom_prompt, idx)\n",
    "            tasks.append(task)\n",
    "            index_to_meta[f\"task-{idx}\"] = (image_name, question)\n",
    "\n",
    "        if not tasks:\n",
    "            print(f\"âœ… No valid tasks for chunk starting at {start_index}\")\n",
    "            continue\n",
    "\n",
    "        # Convert tasks to bytes for upload\n",
    "        jsonl_bytes = \"\\n\".join(json.dumps(task) for task in tasks).encode(\"utf-8\")\n",
    "        file_like = io.BytesIO(jsonl_bytes)\n",
    "\n",
    "        # Upload batch file\n",
    "        batch_file = client.files.create(file=file_like, purpose=\"batch\")\n",
    "        batch_job = client.batches.create(\n",
    "            input_file_id=batch_file.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "\n",
    "        # Save metadata\n",
    "        batch_metadata.append({\n",
    "            \"batch_id\": batch_job.id,\n",
    "            \"start_index\": start_index,\n",
    "            \"size\": len(df),\n",
    "            \"status\": \"submitted\",\n",
    "            \"index_to_meta\": index_to_meta\n",
    "        })\n",
    "\n",
    "        with open(batch_metadata_file, \"w\") as f:\n",
    "            json.dump(batch_metadata, f, indent=4)\n",
    "\n",
    "        print(f\"ðŸŸ¢ Submitted batch {batch_job.id} for chunk starting at {start_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c35c4d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â© Skipping chunk starting at index 0, already submitted\n",
      "â© Skipping chunk starting at index 100, already submitted\n",
      "â© Skipping chunk starting at index 200, already submitted\n",
      "â© Skipping chunk starting at index 300, already submitted\n",
      "â© Skipping chunk starting at index 400, already submitted\n",
      "â© Skipping chunk starting at index 500, already submitted\n",
      "â© Skipping chunk starting at index 600, already submitted\n",
      "â© Skipping chunk starting at index 700, already submitted\n",
      "â© Skipping chunk starting at index 800, already submitted\n",
      "â© Skipping chunk starting at index 900, already submitted\n",
      "â© Skipping chunk starting at index 1000, already submitted\n",
      "â© Skipping chunk starting at index 1100, already submitted\n",
      "â© Skipping chunk starting at index 1200, already submitted\n",
      "â© Skipping chunk starting at index 1300, already submitted\n",
      "â© Skipping chunk starting at index 1400, already submitted\n",
      "â© Skipping chunk starting at index 1500, already submitted\n",
      "â© Skipping chunk starting at index 1600, already submitted\n",
      "â© Skipping chunk starting at index 1700, already submitted\n",
      "â© Skipping chunk starting at index 1800, already submitted\n",
      "â© Skipping chunk starting at index 1900, already submitted\n",
      "â© Skipping chunk starting at index 2000, already submitted\n",
      "â© Skipping chunk starting at index 2100, already submitted\n",
      "â© Skipping chunk starting at index 2200, already submitted\n",
      "â© Skipping chunk starting at index 2300, already submitted\n",
      "â© Skipping chunk starting at index 2400, already submitted\n",
      "â© Skipping chunk starting at index 2500, already submitted\n",
      "â© Skipping chunk starting at index 2600, already submitted\n",
      "â© Skipping chunk starting at index 2700, already submitted\n",
      "â© Skipping chunk starting at index 2800, already submitted\n",
      "â© Skipping chunk starting at index 2900, already submitted\n",
      "â© Skipping chunk starting at index 3000, already submitted\n",
      "â© Skipping chunk starting at index 3100, already submitted\n",
      "â© Skipping chunk starting at index 3200, already submitted\n",
      "â© Skipping chunk starting at index 3300, already submitted\n",
      "â© Skipping chunk starting at index 3400, already submitted\n",
      "â© Skipping chunk starting at index 3500, already submitted\n",
      "â© Skipping chunk starting at index 3600, already submitted\n",
      "â© Skipping chunk starting at index 3700, already submitted\n",
      "â© Skipping chunk starting at index 3800, already submitted\n",
      "â© Skipping chunk starting at index 3900, already submitted\n",
      "â© Skipping chunk starting at index 4000, already submitted\n",
      "â© Skipping chunk starting at index 4100, already submitted\n",
      "â© Skipping chunk starting at index 4200, already submitted\n",
      "â© Skipping chunk starting at index 4300, already submitted\n",
      "â© Skipping chunk starting at index 4400, already submitted\n",
      "â© Skipping chunk starting at index 4500, already submitted\n",
      "â© Skipping chunk starting at index 4600, already submitted\n",
      "â© Skipping chunk starting at index 4700, already submitted\n",
      "â© Skipping chunk starting at index 4800, already submitted\n",
      "â© Skipping chunk starting at index 4900, already submitted\n",
      "â© Skipping chunk starting at index 5000, already submitted\n",
      "â© Skipping chunk starting at index 5100, already submitted\n",
      "â© Skipping chunk starting at index 5200, already submitted\n",
      "â© Skipping chunk starting at index 5300, already submitted\n",
      "â© Skipping chunk starting at index 5400, already submitted\n",
      "â© Skipping chunk starting at index 5500, already submitted\n",
      "â© Skipping chunk starting at index 5600, already submitted\n",
      "â© Skipping chunk starting at index 5700, already submitted\n",
      "â© Skipping chunk starting at index 5800, already submitted\n",
      "â© Skipping chunk starting at index 5900, already submitted\n",
      "â© Skipping chunk starting at index 6000, already submitted\n",
      "â© Skipping chunk starting at index 6100, already submitted\n",
      "â© Skipping chunk starting at index 6200, already submitted\n",
      "â© Skipping chunk starting at index 6300, already submitted\n",
      "â© Skipping chunk starting at index 6400, already submitted\n",
      "â© Skipping chunk starting at index 6500, already submitted\n",
      "â© Skipping chunk starting at index 6600, already submitted\n",
      "â© Skipping chunk starting at index 6700, already submitted\n",
      "â© Skipping chunk starting at index 6800, already submitted\n",
      "â© Skipping chunk starting at index 6900, already submitted\n",
      "â© Skipping chunk starting at index 7000, already submitted\n",
      "â© Skipping chunk starting at index 7100, already submitted\n",
      "â© Skipping chunk starting at index 7200, already submitted\n",
      "â© Skipping chunk starting at index 7300, already submitted\n",
      "â© Skipping chunk starting at index 7400, already submitted\n",
      "â© Skipping chunk starting at index 7500, already submitted\n",
      "â© Skipping chunk starting at index 7600, already submitted\n",
      "â© Skipping chunk starting at index 7700, already submitted\n",
      "â© Skipping chunk starting at index 7800, already submitted\n",
      "â© Skipping chunk starting at index 7900, already submitted\n",
      "â© Skipping chunk starting at index 8000, already submitted\n",
      "â© Skipping chunk starting at index 8100, already submitted\n",
      "â© Skipping chunk starting at index 8200, already submitted\n",
      "â© Skipping chunk starting at index 8300, already submitted\n",
      "â© Skipping chunk starting at index 8400, already submitted\n",
      "â© Skipping chunk starting at index 8500, already submitted\n",
      "â© Skipping chunk starting at index 8600, already submitted\n",
      "â© Skipping chunk starting at index 8700, already submitted\n",
      "â© Skipping chunk starting at index 8800, already submitted\n",
      "â© Skipping chunk starting at index 8900, already submitted\n",
      "â© Skipping chunk starting at index 9000, already submitted\n",
      "â© Skipping chunk starting at index 9100, already submitted\n",
      "â© Skipping chunk starting at index 9200, already submitted\n",
      "â© Skipping chunk starting at index 9300, already submitted\n",
      "â© Skipping chunk starting at index 9400, already submitted\n",
      "â© Skipping chunk starting at index 9500, already submitted\n",
      "â© Skipping chunk starting at index 9600, already submitted\n",
      "â© Skipping chunk starting at index 9700, already submitted\n",
      "â© Skipping chunk starting at index 9800, already submitted\n",
      "â© Skipping chunk starting at index 9900, already submitted\n",
      "â© Skipping chunk starting at index 10000, already submitted\n",
      "â© Skipping chunk starting at index 10100, already submitted\n",
      "â© Skipping chunk starting at index 10200, already submitted\n",
      "â© Skipping chunk starting at index 10300, already submitted\n",
      "â© Skipping chunk starting at index 10400, already submitted\n",
      "â© Skipping chunk starting at index 10500, already submitted\n",
      "â© Skipping chunk starting at index 10600, already submitted\n",
      "â© Skipping chunk starting at index 10700, already submitted\n",
      "â© Skipping chunk starting at index 10800, already submitted\n",
      "â© Skipping chunk starting at index 10900, already submitted\n",
      "â© Skipping chunk starting at index 11000, already submitted\n",
      "â© Skipping chunk starting at index 11100, already submitted\n",
      "â© Skipping chunk starting at index 11200, already submitted\n",
      "â© Skipping chunk starting at index 11300, already submitted\n",
      "â© Skipping chunk starting at index 11400, already submitted\n",
      "â© Skipping chunk starting at index 11500, already submitted\n",
      "â© Skipping chunk starting at index 11600, already submitted\n",
      "â© Skipping chunk starting at index 11700, already submitted\n",
      "â© Skipping chunk starting at index 11800, already submitted\n"
     ]
    }
   ],
   "source": [
    "submit_batches(INPUT_CSV, IMAGE_BASE_FOLDER, CUSTOM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fda8e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_and_save_results(output_csv, batch_metadata_file=\"openai_results/batch_jobs_metadata_4o.json\"):\n",
    "    with open(batch_metadata_file, \"r\") as f:\n",
    "        batch_metadata = json.load(f)\n",
    "\n",
    "    for meta in batch_metadata:\n",
    "        batch_id = meta[\"batch_id\"]\n",
    "        start_index = meta[\"start_index\"]\n",
    "        index_to_meta = meta[\"index_to_meta\"]\n",
    "\n",
    "        if meta.get(\"status\") == \"completed\":\n",
    "            continue  # already processed\n",
    "\n",
    "        batch_job = client.batches.retrieve(batch_id)\n",
    "        status = batch_job.status\n",
    "        print(f\"â³ Batch {batch_id} status: {status}\")\n",
    "\n",
    "        if status != \"completed\":\n",
    "            print(f\"âŒ Batch {batch_id} not completed yet\")\n",
    "            continue\n",
    "\n",
    "        # Download output file\n",
    "        output_file = client.files.content(batch_job.output_file_id)\n",
    "        lines = output_file.text.splitlines()\n",
    "\n",
    "        results = []\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            try:\n",
    "                content = data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "                if isinstance(content, list):\n",
    "                    text = \"\".join([c.get(\"text\", \"\") for c in content if c.get(\"type\") == \"text\"])\n",
    "                else:\n",
    "                    text = content\n",
    "                results.append(text)\n",
    "            except Exception as e:\n",
    "                print(\"Skipping malformed line:\", e)\n",
    "\n",
    "        # Write results mapped back to original CSV\n",
    "        with open(output_csv, mode=\"a\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "            writer = csv.DictWriter(f_out, fieldnames=[\"image_name\", \"question\", \"llm_answer\"])\n",
    "            if f_out.tell() == 0:\n",
    "                writer.writeheader()\n",
    "\n",
    "            # Map results using index_to_meta\n",
    "            for idx, answer in enumerate(results):\n",
    "                task_key = f\"task-{start_index + idx}\"\n",
    "                image_name, question = index_to_meta.get(task_key, (\"UNKNOWN\", \"UNKNOWN\"))\n",
    "                writer.writerow({\n",
    "                    \"image_name\": image_name,\n",
    "                    \"question\": question,\n",
    "                    \"llm_answer\": answer if answer else \"âŒ No answer returned\"\n",
    "                })\n",
    "\n",
    "        # Update metadata status\n",
    "        meta[\"status\"] = \"completed\"\n",
    "        with open(batch_metadata_file, \"w\") as f:\n",
    "            json.dump(batch_metadata, f, indent=4)\n",
    "\n",
    "        print(f\"âœ… Results from batch {batch_id} saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9596f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Batch batch_68cd25b91fc8819096aee7d769906883 status: failed\n",
      "âŒ Batch batch_68cd25b91fc8819096aee7d769906883 not completed yet\n",
      "â³ Batch batch_68cd2606dd9c8190aabfe0c346c75af4 status: failed\n",
      "âŒ Batch batch_68cd2606dd9c8190aabfe0c346c75af4 not completed yet\n",
      "â³ Batch batch_68cd319adb1c8190a4da0b6fe864efa0 status: failed\n",
      "âŒ Batch batch_68cd319adb1c8190a4da0b6fe864efa0 not completed yet\n"
     ]
    }
   ],
   "source": [
    "poll_and_save_results(OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaf1fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def rerun_failed_batches(input_csv, base_folder, custom_prompt, batch_metadata_file=\"openai_results/batch_jobs_metadata.json\"):\n",
    "    \"\"\"\n",
    "    Rerun batches that failed using the saved metadata.\n",
    "    \"\"\"\n",
    "    # Load existing metadata\n",
    "    try:\n",
    "        with open(batch_metadata_file, \"r\") as f:\n",
    "            batch_metadata = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Metadata file not found\")\n",
    "        return\n",
    "\n",
    "    rerun_metadata = []\n",
    "    for meta in batch_metadata:\n",
    "        if meta.get(\"status\") == \"failed\":\n",
    "            start_index = meta[\"start_index\"]\n",
    "            size = meta[\"size\"]\n",
    "\n",
    "            print(f\"ðŸ”„ Rerunning failed batch {meta['batch_id']} (chunk {start_index}â€“{start_index+size-1})\")\n",
    "\n",
    "            # Load the corresponding CSV slice\n",
    "            df = pd.read_csv(input_csv, skiprows=range(1, start_index+1), nrows=size)\n",
    "\n",
    "            tasks = []\n",
    "            index_to_meta = {}\n",
    "            for idx, row in df.iterrows():\n",
    "                image_name, question = row['image_name'], row['question']\n",
    "                image_path = find_image_recursive(base_folder, image_name)\n",
    "\n",
    "                if not image_path:\n",
    "                    continue\n",
    "\n",
    "                task = ask_image_question(image_path, question, custom_prompt, idx)\n",
    "                tasks.append(task)\n",
    "                index_to_meta[f\"task-{idx}\"] = (image_name, question)\n",
    "\n",
    "            if not tasks:\n",
    "                print(f\"âš ï¸ No tasks to rerun for chunk starting at {start_index}\")\n",
    "                continue\n",
    "\n",
    "            # Convert to JSONL and upload\n",
    "            jsonl_bytes = \"\\n\".join(json.dumps(task) for task in tasks).encode(\"utf-8\")\n",
    "            file_like = io.BytesIO(jsonl_bytes)\n",
    "\n",
    "            batch_file = client.files.create(file=file_like, purpose=\"batch\")\n",
    "            batch_job = client.batches.create(\n",
    "                input_file_id=batch_file.id,\n",
    "                endpoint=\"/v1/chat/completions\",\n",
    "                completion_window=\"24h\"\n",
    "            )\n",
    "\n",
    "            # Update metadata\n",
    "            meta.update({\n",
    "                \"rerun_batch_id\": batch_job.id,\n",
    "                \"status\": \"resubmitted\",\n",
    "                \"index_to_meta\": index_to_meta\n",
    "            })\n",
    "            rerun_metadata.append(meta)\n",
    "\n",
    "            print(f\"ðŸŸ¢ Resubmitted as batch {batch_job.id}\")\n",
    "\n",
    "    # Save updated metadata\n",
    "    if rerun_metadata:\n",
    "        with open(batch_metadata_file, \"w\") as f:\n",
    "            json.dump(batch_metadata, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db41c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun_incomplete_batches(\n",
    "    input_csv,\n",
    "    base_folder,\n",
    "    custom_prompt,\n",
    "    batch_metadata_file=\"openai_results/batch_jobs_metadata.json\"\n",
    "):\n",
    "    try:\n",
    "        with open(batch_metadata_file, \"r\") as f:\n",
    "            batch_metadata = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ No batch metadata file found.\")\n",
    "        return\n",
    "\n",
    "    for meta in batch_metadata:\n",
    "        if meta.get(\"status\") == \"completed\":\n",
    "            continue  # skip finished ones\n",
    "\n",
    "        start_index = meta[\"start_index\"]\n",
    "        size = meta[\"size\"]\n",
    "\n",
    "        print(f\"ðŸ”„ Rerunning batch {meta['batch_id']} (status={meta['status']}) covering rows {start_index}â€“{start_index+size-1}\")\n",
    "\n",
    "        # reload chunk from CSV\n",
    "        df = pd.read_csv(input_csv, skiprows=range(1, start_index+1), nrows=size)\n",
    "\n",
    "        tasks = []\n",
    "        index_to_meta = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            image_name, question = row['image_name'], row['question']\n",
    "            image_path = find_image_recursive(base_folder, image_name)\n",
    "            if not image_path:\n",
    "                continue\n",
    "            task = ask_image_question(image_path, question, custom_prompt, idx)\n",
    "            tasks.append(task)\n",
    "            index_to_meta[f\"task-{idx}\"] = (image_name, question)\n",
    "\n",
    "        if not tasks:\n",
    "            print(\"âš ï¸ No tasks found for rerun.\")\n",
    "            continue\n",
    "\n",
    "        # upload new file + create new batch\n",
    "        buf = io.BytesIO()\n",
    "        for obj in tasks:\n",
    "            buf.write((json.dumps(obj) + \"\\n\").encode(\"utf-8\"))\n",
    "        buf.seek(0)\n",
    "\n",
    "        batch_file = client.files.create(file=buf, purpose=\"batch\")\n",
    "        batch_job = client.batches.create(input_file_id=batch_file.id, endpoint=\"/v1/chat/completions\", completion_window=\"24h\")\n",
    "\n",
    "        # update metadata\n",
    "        meta.update({\n",
    "            \"batch_id\": batch_job.id,\n",
    "            \"status\": \"submitted\",\n",
    "            \"index_to_meta\": index_to_meta,\n",
    "        })\n",
    "\n",
    "    with open(batch_metadata_file, \"w\") as f:\n",
    "        json.dump(batch_metadata, f, indent=4)\n",
    "\n",
    "    print(\"âœ… Incomplete batches resubmitted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d76d0ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Rerunning batch batch_68cc319d7c008190b11e31b6e875368a (status=failed) covering rows 2300â€“2399\n",
      "ðŸ”„ Rerunning batch batch_68cc31dcbad4819093a44e3ae8989c6b (status=failed) covering rows 2400â€“2499\n",
      "ðŸ”„ Rerunning batch batch_68cc3226c3ec819089ca9cc25c7f691a (status=failed) covering rows 8100â€“8199\n",
      "âœ… Incomplete batches resubmitted\n"
     ]
    }
   ],
   "source": [
    "rerun_incomplete_batches(INPUT_CSV, IMAGE_BASE_FOLDER, CUSTOM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec6a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def poll_and_update_batches(batch_metadata_file=\"openai_results/batch_jobs_metadata.json\", poll_interval=30):\n",
    "    \"\"\"\n",
    "    Poll all submitted batch jobs and update their status in metadata.\n",
    "    Saves updated metadata after every cycle.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(batch_metadata_file, \"r\") as f:\n",
    "            batch_metadata = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ No batch metadata file found.\")\n",
    "        return\n",
    "\n",
    "    all_done = False\n",
    "    while not all_done:\n",
    "        all_done = True\n",
    "        for meta in batch_metadata:\n",
    "            batch_id = meta[\"batch_id\"]\n",
    "            status = meta.get(\"status\", \"unknown\")\n",
    "\n",
    "            # Skip completed or failed ones if you only want live polling\n",
    "            if status in [\"completed\", \"failed\", \"expired\", \"canceled\"]:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                job = client.batches.retrieve(batch_id)\n",
    "                new_status = job.status\n",
    "                if new_status != status:\n",
    "                    print(f\"ðŸ”„ Batch {batch_id} status updated: {status} â†’ {new_status}\")\n",
    "                    meta[\"status\"] = new_status\n",
    "                    # also store finish_time if available\n",
    "                    if hasattr(job, \"completed_at\") and job.completed_at:\n",
    "                        meta[\"completed_at\"] = job.completed_at\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Could not retrieve batch {batch_id}: {e}\")\n",
    "\n",
    "        # save metadata after each poll cycle\n",
    "        with open(batch_metadata_file, \"w\") as f:\n",
    "            json.dump(batch_metadata, f, indent=4)\n",
    "\n",
    "        # check if all jobs are in terminal states\n",
    "        if any(m[\"status\"] not in [\"completed\", \"failed\", \"expired\", \"canceled\"] for m in batch_metadata):\n",
    "            all_done = False\n",
    "            print(f\"â³ Waiting {poll_interval}s before next check...\")\n",
    "            time.sleep(poll_interval)\n",
    "\n",
    "    print(\"âœ… All batches reached a terminal state.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69369d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Batch batch_68cc319d7c008190b11e31b6e875368a status updated: submitted â†’ failed\n",
      "ðŸ”„ Batch batch_68cc31dcbad4819093a44e3ae8989c6b status updated: submitted â†’ failed\n",
      "ðŸ”„ Batch batch_68cc3226c3ec819089ca9cc25c7f691a status updated: submitted â†’ validating\n",
      "â³ Waiting 30s before next check...\n",
      "ðŸ”„ Batch batch_68cc3226c3ec819089ca9cc25c7f691a status updated: validating â†’ failed\n",
      "âœ… All batches reached a terminal state.\n"
     ]
    }
   ],
   "source": [
    "poll_and_update_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0117d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
